---  
output:html_document  
toc:true  
toc_depth:2  
---
```{r, echo=FALSE,results='hide'}
##ProjCodeReport_July21_327pm version: Add accuracy and time vs #vars plot
```
**Coursera Practical Machine Learning Project July 2015:   
Machine Learning Model From Weight Lifting Exercises Dataset**  
Ram Krishnan (May 19, 2015)  
**Executive Summary**  
This dataset has been analyzed by many researchers (Refs 2-3) who have all concluded that Random Forest is the best algorithm and is accurate to >99%! One researcher has found that other methods (Ref 2) are significantly less accurate. We will use the Random Forest method based on those earlier findings but extend the results to answer the following question:   
*How can the results be used to build a practical appliance that can provide real-time feedback to the weight-lifter?*   
The appliance must be low-cost (e.g. the FitBit), thus have minimum hardware i.e. the smallest number of sensors. The original dataset has 52 variables i.e. 52 sensors that provide feedback. That is clearly too many for a practical appliance that could be sold for consumer electronics type prices. Additionally, fewer sensors will result in shorter processing time for the predictor model which is necessary for real-time feedback to the weight-lifter. To determine which sensors are important and must be left in a practical device, it also helps to have a more interpretable model such as Random Forests as compared to Principal Components where the outputs from many sensors could get merged into a single feedback signal. To accomplish the objective of fewest sensors, we determined that only 8 variables were most important using the Importance matrix component of the Random Forest model. We then examined the accuracy of a predictor using only these 8 variables. The full model (52 variables) has a testing accuracy of 99.5% and the reduced, 8-variable model has an accuracy of 98.7% which is quite acceptable especially for a significantly lower cost and complexity. As a bonus, the reduced (8-variable) predictor requires 0.314 secs for real-time predictions compared to the full (52-variable) preditor which requires 0.409 secs, a 23% reduction in prediction time. The 8-sensor model was also tested against the 20 observation testing dataset and the predictions all passed the automated submission test.
```{r downloadData, echo=FALSE,results='hide',cache=TRUE}
library(lattice,quietly = TRUE,verbose = FALSE)
library(ggplot2,quietly = TRUE,verbose = FALSE)
library(randomForest,quietly = TRUE,verbose = FALSE)
library(downloader,quietly = TRUE,verbose = FALSE)
library(caret,quietly = TRUE,verbose = FALSE)
library(AppliedPredictiveModeling,quietly = TRUE,verbose = FALSE)
download("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="training.csv")
download("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile="testing.csv")
```
**Exploratory Data Analysis**  
First, we pre-process the training data to remove all irrelevant data (first 7 columns), columns containing all zeros and columns containing factor variables (which vary very little and therefore contribute nothing to the model). Next, we add the output (factor) variable "classe" back in.  
```{r ExploreData, echo=FALSE,results='hide',cache=TRUE}
training <- read.csv("training.csv")
testing <- read.csv("testing.csv")
training1 <- training[,-c(1:7)]
testing1 <- testing[,-c(1:7)]
```
```{r FormTrainTest, echo=FALSE,results='hide',cache=FALSE}
colClass <- sapply(training1, class)
colF <- which(colClass=="factor")
training2 <- training1[, -colF]
testing2 <- testing1[, -colF]
colSums.NA <- colSums(is.na(training2))
training3 <- training2[, which(colSums.NA==0)]
training.Processed <- cbind(training3, classe = training$classe)
testing3 <- testing2[, which(colSums.NA==0)]
testing.Processed <- cbind(testing3, classe = testing$problem_id)
```
Observing that the testing data does not have the classe variable, hence cannot be used for validation, we create a separate validation set by splitting the training set into 75% for training and 25% for validation.   
**Modeling and Prediction**  
We build a model using the randomForest() command set rather than the train() command set because it was found to process in <5 minutes compared to train("rf") which took 1.23 hours! Of course, train("rf") could probably be speeded up by changing the default values but since randomForest() results in great accuracy (>99%), it was the default command set. Next we use the created validation test set to validate the result with the confusion matrix and the test accuracy. Here, then are the results of the 52-variable model followed by the accuracy of the 52-variable model.
```{r FullModel, echo=FALSE,cache=TRUE}
library(caret,quietly = TRUE,verbose = FALSE)
library(AppliedPredictiveModeling,quietly = TRUE,verbose = FALSE)
set.seed(123)
useData <- createDataPartition(y=training.Processed$classe, p=0.75, list=FALSE)
myTraining <- training.Processed[useData,]
myTesting <- training.Processed[-useData,]
library(randomForest,quietly = TRUE,verbose = FALSE)
set.seed(1234)
modFit.Full_RF <- randomForest(classe~., data=myTraining, importance = TRUE, proximity = TRUE)
t1 <- Sys.time()
pred.RF <- predict(modFit.Full_RF, myTesting)
t2 <- Sys.time()
Full_RF.PredictTime <- difftime(t2,t1)
confusion.Full_RF <- confusionMatrix(pred.RF, myTesting$classe)
#print(modFit.Full_RF$call)
print(modFit.Full_RF)
print(confusion.Full_RF$overall)
##cat("Full RF model prediction time:",Full_RF.PredictTime)
```
The randomForest command conveniently provides an Importance matrix which lists the variables in order of importance based on the mean decrease in the Gini index. We sort the variables according to importance and keep the top 10 (mean decrease in Gini scores beyond var 10 are relatively low). The most important variables are combined with the "classe" output variable to form a new training set and testing set. A model is created using the randomForest command again. Here are the 10 most important variables followed by the table and charts showing the accuracy versus the number of variables and the prediction time versus the number of variables. From the "#Vars vs Accuracy" chart (below) and the "#Vars vs Prediction Time" chart, it is obvious that 8 variables gives the best accuracy and time (not as good as 52 variables, but close), so we determine that the 8-variable model is optimum for a practical feedback system. Finally, we plot the 8-variable confusion matrix to visually check the accuracy of each output level and see that the levels are accurately centered on the actuals and >98% accurate.  
```{r, echo=FALSE,cache=TRUE}
ImpVarTemp <- sort(modFit.Full_RF$importance[,7],decreasing = TRUE)
ImpVar <- ImpVarTemp[1:10]
cat("10 Most Imp Var:",names(ImpVar),sep = "  ")
confMat.Imp <- confusion.Full_RF                ##initialize
OutputMat <- matrix(0,nrow=7,ncol=3)            ##initialize
colnames(OutputMat) <- c("NoOfVars","Accuracy","PredictTime")
OutputMat[7,1] <- 52                            ##variables in Full Model
OutputMat[7,2] <- confusion.Full_RF$overall[1]  #Pre-fill full model accuracy
OutputMat[7,3] <- Full_RF.PredictTime           #Pre-fill full model predictor time
for(i in 5:10){
  ImpVar_i <- ImpVar[1:i]
  training.Imp <- myTraining[,names(ImpVar_i)]
  testing.Imp <- myTesting[,names(ImpVar_i)]
  modFit.Imp <- randomForest(myTraining$classe~., data=training.Imp, importance = TRUE, proximity = TRUE)
  t3 <- Sys.time()
  Imp_RF.predictor <- predict(modFit.Imp,testing.Imp)
  t4 <- Sys.time()
  ImpVar.PredictTime <- difftime(t4,t3)
  OutputMat[i-4,1] <- i                         #No of variables in this model
  OutputMat[i-4,3]<-ImpVar.PredictTime          ##Save process time in column 1
  #cat("Top",i,"Var RF model prediction time:",ImpVar.PredictTime)
  confMat.Imp <- confusionMatrix(Imp_RF.predictor,myTesting$classe)
  if(i==8){table2 <- confMat.Imp$table}         ##save predictor table for optimum #vars = 7
  OutputMat[i-4,2]<-confMat.Imp$overall[1]   ##Save accuracy in column 1
  ##cat("Now computing i =",i,confMat.Imp$overall)
}
cat("No of vars vs Accuracy and Predict Time:","\n")
print(OutputMat)
```
```{r, echo=FALSE,cache=TRUE}
#screen(new=TRUE)
#split.screen(c(2, 1))                # split display into upper and lower screens
#split.screen(c(1, 2), screen = 1)    # now split the top half into 2
x <- OutputMat[-7,1]
y <- OutputMat[-7,2]
#screen(1)          # prepare upper for output
#par(pin=c(3,3))
plot(x,y, xlab = "# of Vars", ylab = "Accuracy",col = "red", pch = 19, main = "Accuracy vs # of Vars")
z <- OutputMat[-7,3]
#screen(new=TRUE)
#screen(2)                     #prepare upper right panel for plot
#par(pin=c(3,3))
plot(x,z, xlab = "# of Vars", ylab = "Predict Time",col = "blue", pch = 19, main = "Predict Time vs # of Vars")
##Plot random forest confusion matrix
library(som)
library(reshape2)
table2.normalized <- normalize(table2)
colnames(table2.normalized) <- rownames(table2.normalized)
table2.melt <- melt(table2.normalized)
names(table2.melt) <- c("Prediction","Reference","NormFreq")
plot2 <- ggplot(table2.melt)
plot3 <-plot2 + geom_tile(aes(x=Reference, y=Prediction, fill=NormFreq)) + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") +labs(title = "Normalized Confusion Matrix, Random Forest w/ Top 8 Var")
#screen(2) # prepare screen 4 for output
#screen(new=TRUE)
plot3
```
Lastly, the given test set is used to check the prediction accuracy of the 8-variable model. These predictions were then submitted to the automated grading algorithm and found to be all correct.  
```{r, echo=FALSE,cache=FALSE}
##Predict with test data and check accuracy
predictionFinal <- predict(modFit.Imp, testing.Processed)
print("Test set Prediction Using Top 8 Variables RF Model:")
print(predictionFinal)
```  
**References:**    
1. "An Introduction to Statistical Learning", James, Witten, Hastie, Tibshirani, Springer    
2. "Machine Learning for Weight Lifting Exercises Data", Shiming Zhou, http://shinezhou9.github.io/MachineLearningProject1/   
3. "Practical Machine Learning: Peer Assesment", Rithesh Kumar, http://www.rpubs.com/ritheshkumar95/35118

